{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "ec4f869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18418f51",
   "metadata": {},
   "source": [
    "Question 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "29cb64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "386f80f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "b19c601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "cb21accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "head=soup.find('span',class_=\"mw-headline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "2a2dfb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Wikipedia'"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "81610dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"From today's featured list\",\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head=[]#this list will contain all the header tags \n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    head.append(i.text)\n",
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe02fb6",
   "metadata": {},
   "source": [
    "Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "e1281445",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "38bb1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "page2=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "28df8a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Shawshank', 'Redemption'],\n",
       " ['The', 'Godfather'],\n",
       " ['The', 'Dark', 'Knight'],\n",
       " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Return', 'of', 'the', 'King'],\n",
       " [\"Schindler's\", 'List'],\n",
       " ['The', 'Godfather', 'Part', 'II'],\n",
       " ['12', 'Angry', 'Men'],\n",
       " ['Pulp', 'Fiction'],\n",
       " ['Inception'],\n",
       " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Two', 'Towers'],\n",
       " ['Fight', 'Club'],\n",
       " ['The',\n",
       "  'Lord',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Rings:',\n",
       "  'The',\n",
       "  'Fellowship',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Ring'],\n",
       " ['Forrest', 'Gump'],\n",
       " ['Il', 'buono,', 'il', 'brutto,', 'il', 'cattivo'],\n",
       " ['The', 'Matrix'],\n",
       " ['Goodfellas'],\n",
       " ['The', 'Empire', 'Strikes', 'Back'],\n",
       " ['One', 'Flew', 'Over', 'the', \"Cuckoo's\", 'Nest'],\n",
       " ['Top', 'Gun:', 'Maverick'],\n",
       " ['Interstellar'],\n",
       " ['Cidade', 'de', 'Deus'],\n",
       " ['Sen', 'to', 'Chihiro', 'no', 'kamikakushi'],\n",
       " ['Saving', 'Private', 'Ryan'],\n",
       " ['The', 'Green', 'Mile'],\n",
       " ['La', 'vita', 'è', 'bella'],\n",
       " ['Se7en'],\n",
       " ['Terminator', '2:', 'Judgment', 'Day'],\n",
       " ['The', 'Silence', 'of', 'the', 'Lambs'],\n",
       " ['Star', 'Wars'],\n",
       " ['Seppuku'],\n",
       " ['Shichinin', 'no', 'samurai'],\n",
       " [\"It's\", 'a', 'Wonderful', 'Life'],\n",
       " ['Gisaengchung'],\n",
       " ['Whiplash'],\n",
       " ['The', 'Intouchables'],\n",
       " ['The', 'Prestige'],\n",
       " ['The', 'Departed'],\n",
       " ['The', 'Pianist'],\n",
       " ['Gladiator'],\n",
       " ['American', 'History', 'X'],\n",
       " ['The', 'Usual', 'Suspects'],\n",
       " ['Léon'],\n",
       " ['The', 'Lion', 'King'],\n",
       " ['Nuovo', 'Cinema', 'Paradiso'],\n",
       " ['Hotaru', 'no', 'haka'],\n",
       " ['Back', 'to', 'the', 'Future'],\n",
       " ['Apocalypse', 'Now'],\n",
       " ['Alien'],\n",
       " ['Once', 'Upon', 'a', 'Time', 'in', 'the', 'West'],\n",
       " ['Psycho']]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "top100=[]#this list will contain all the names of the movies in the IMDB's top 100 list\n",
    "for i in soup.find_all('h3',class_=\"lister-item-header\"):\n",
    "    top100.append(i.text.split()[1:-1])\n",
    "top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "1208e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2=BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "3d16a9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Shawshank', 'Redemption'],\n",
       " ['The', 'Godfather'],\n",
       " ['The', 'Dark', 'Knight'],\n",
       " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Return', 'of', 'the', 'King'],\n",
       " [\"Schindler's\", 'List'],\n",
       " ['The', 'Godfather', 'Part', 'II'],\n",
       " ['12', 'Angry', 'Men'],\n",
       " ['Pulp', 'Fiction'],\n",
       " ['Inception'],\n",
       " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Two', 'Towers'],\n",
       " ['Fight', 'Club'],\n",
       " ['The',\n",
       "  'Lord',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Rings:',\n",
       "  'The',\n",
       "  'Fellowship',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Ring'],\n",
       " ['Forrest', 'Gump'],\n",
       " ['Il', 'buono,', 'il', 'brutto,', 'il', 'cattivo'],\n",
       " ['The', 'Matrix'],\n",
       " ['Goodfellas'],\n",
       " ['The', 'Empire', 'Strikes', 'Back'],\n",
       " ['One', 'Flew', 'Over', 'the', \"Cuckoo's\", 'Nest'],\n",
       " ['Top', 'Gun:', 'Maverick'],\n",
       " ['Interstellar'],\n",
       " ['Cidade', 'de', 'Deus'],\n",
       " ['Sen', 'to', 'Chihiro', 'no', 'kamikakushi'],\n",
       " ['Saving', 'Private', 'Ryan'],\n",
       " ['The', 'Green', 'Mile'],\n",
       " ['La', 'vita', 'è', 'bella'],\n",
       " ['Se7en'],\n",
       " ['Terminator', '2:', 'Judgment', 'Day'],\n",
       " ['The', 'Silence', 'of', 'the', 'Lambs'],\n",
       " ['Star', 'Wars'],\n",
       " ['Seppuku'],\n",
       " ['Shichinin', 'no', 'samurai'],\n",
       " [\"It's\", 'a', 'Wonderful', 'Life'],\n",
       " ['Gisaengchung'],\n",
       " ['Whiplash'],\n",
       " ['The', 'Intouchables'],\n",
       " ['The', 'Prestige'],\n",
       " ['The', 'Departed'],\n",
       " ['The', 'Pianist'],\n",
       " ['Gladiator'],\n",
       " ['American', 'History', 'X'],\n",
       " ['The', 'Usual', 'Suspects'],\n",
       " ['Léon'],\n",
       " ['The', 'Lion', 'King'],\n",
       " ['Nuovo', 'Cinema', 'Paradiso'],\n",
       " ['Hotaru', 'no', 'haka'],\n",
       " ['Back', 'to', 'the', 'Future'],\n",
       " ['Apocalypse', 'Now'],\n",
       " ['Alien'],\n",
       " ['Once', 'Upon', 'a', 'Time', 'in', 'the', 'West'],\n",
       " ['Psycho'],\n",
       " ['Rear', 'Window'],\n",
       " ['Casablanca'],\n",
       " ['Modern', 'Times'],\n",
       " ['City', 'Lights'],\n",
       " ['Capharnaüm'],\n",
       " ['Joker', '(I)'],\n",
       " ['Kimi', 'no', 'na', 'wa.'],\n",
       " ['Spider-Man:', 'Into', 'the', 'Spider-Verse'],\n",
       " ['Avengers:', 'Endgame'],\n",
       " ['Avengers:', 'Infinity', 'War'],\n",
       " ['Coco', '(I)'],\n",
       " ['Django', 'Unchained'],\n",
       " ['The', 'Dark', 'Knight', 'Rises'],\n",
       " ['3', 'Idiots'],\n",
       " ['WALL·E'],\n",
       " ['The', 'Lives', 'of', 'Others'],\n",
       " ['Oldeuboi'],\n",
       " ['Memento'],\n",
       " ['American', 'Beauty'],\n",
       " ['Mononoke-hime'],\n",
       " ['Braveheart'],\n",
       " ['Idi', 'i', 'smotri'],\n",
       " ['Aliens'],\n",
       " ['Amadeus'],\n",
       " ['Raiders', 'of', 'the', 'Lost', 'Ark'],\n",
       " ['Das', 'Boot'],\n",
       " ['The', 'Shining'],\n",
       " ['Tengoku', 'to', 'jigoku'],\n",
       " ['Dr.',\n",
       "  'Strangelove',\n",
       "  'or:',\n",
       "  'How',\n",
       "  'I',\n",
       "  'Learned',\n",
       "  'to',\n",
       "  'Stop',\n",
       "  'Worrying',\n",
       "  'and',\n",
       "  'Love',\n",
       "  'the',\n",
       "  'Bomb'],\n",
       " ['Witness', 'for', 'the', 'Prosecution'],\n",
       " ['Paths', 'of', 'Glory'],\n",
       " ['Sunset', 'Blvd.'],\n",
       " ['The', 'Great', 'Dictator'],\n",
       " ['Jagten'],\n",
       " ['Toy', 'Story', '3'],\n",
       " ['Inglourious', 'Basterds'],\n",
       " ['Eternal', 'Sunshine', 'of', 'the', 'Spotless', 'Mind'],\n",
       " ['Requiem', 'for', 'a', 'Dream'],\n",
       " ['Good', 'Will', 'Hunting'],\n",
       " ['Toy', 'Story'],\n",
       " ['Reservoir', 'Dogs'],\n",
       " ['Once', 'Upon', 'a', 'Time', 'in', 'America'],\n",
       " ['Star', 'Wars:', 'Episode', 'VI', '-', 'Return', 'of', 'the', 'Jedi'],\n",
       " ['2001:', 'A', 'Space', 'Odyssey'],\n",
       " ['Lawrence', 'of', 'Arabia'],\n",
       " ['North', 'by', 'Northwest'],\n",
       " ['Vertigo'],\n",
       " [\"Singin'\", 'in', 'the', 'Rain'],\n",
       " ['Citizen', 'Kane'],\n",
       " ['M', '-', 'Eine', 'Stadt', 'sucht', 'einen', 'Mörder']]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this list will contain all the names of the movies in the IMDB's top 100 list of the second page\n",
    "for i in soup2.find_all('h3',class_=\"lister-item-header\"):\n",
    "    top100.append(i.text.split()[1:-1])\n",
    "top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "5fccca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "1558d048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(1994)'],\n",
       " ['(1972)'],\n",
       " ['(2008)'],\n",
       " ['(2003)'],\n",
       " ['(1993)'],\n",
       " ['(1974)'],\n",
       " ['(1957)'],\n",
       " ['(1994)'],\n",
       " ['(2010)'],\n",
       " ['(2002)'],\n",
       " ['(1999)'],\n",
       " ['(2001)'],\n",
       " ['(1994)'],\n",
       " ['(1966)'],\n",
       " ['(1999)'],\n",
       " ['(1990)'],\n",
       " ['(1980)'],\n",
       " ['(1975)'],\n",
       " ['(2022)'],\n",
       " ['(2014)'],\n",
       " ['(2002)'],\n",
       " ['(2001)'],\n",
       " ['(1998)'],\n",
       " ['(1999)'],\n",
       " ['(1997)'],\n",
       " ['(1995)'],\n",
       " ['(1991)'],\n",
       " ['(1991)'],\n",
       " ['(1977)'],\n",
       " ['(1962)'],\n",
       " ['(1954)'],\n",
       " ['(1946)'],\n",
       " ['(2019)'],\n",
       " ['(2014)'],\n",
       " ['(2011)'],\n",
       " ['(2006)'],\n",
       " ['(2006)'],\n",
       " ['(2002)'],\n",
       " ['(2000)'],\n",
       " ['(1998)'],\n",
       " ['(1995)'],\n",
       " ['(1994)'],\n",
       " ['(1994)'],\n",
       " ['(1988)'],\n",
       " ['(1988)'],\n",
       " ['(1985)'],\n",
       " ['(1979)'],\n",
       " ['(1979)'],\n",
       " ['(1968)'],\n",
       " ['(1960)']]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "for i in soup.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text.split())\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "80d5e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(1994)'],\n",
       " ['(1972)'],\n",
       " ['(2008)'],\n",
       " ['(2003)'],\n",
       " ['(1993)'],\n",
       " ['(1974)'],\n",
       " ['(1957)'],\n",
       " ['(1994)'],\n",
       " ['(2010)'],\n",
       " ['(2002)'],\n",
       " ['(1999)'],\n",
       " ['(2001)'],\n",
       " ['(1994)'],\n",
       " ['(1966)'],\n",
       " ['(1999)'],\n",
       " ['(1990)'],\n",
       " ['(1980)'],\n",
       " ['(1975)'],\n",
       " ['(2022)'],\n",
       " ['(2014)'],\n",
       " ['(2002)'],\n",
       " ['(2001)'],\n",
       " ['(1998)'],\n",
       " ['(1999)'],\n",
       " ['(1997)'],\n",
       " ['(1995)'],\n",
       " ['(1991)'],\n",
       " ['(1991)'],\n",
       " ['(1977)'],\n",
       " ['(1962)'],\n",
       " ['(1954)'],\n",
       " ['(1946)'],\n",
       " ['(2019)'],\n",
       " ['(2014)'],\n",
       " ['(2011)'],\n",
       " ['(2006)'],\n",
       " ['(2006)'],\n",
       " ['(2002)'],\n",
       " ['(2000)'],\n",
       " ['(1998)'],\n",
       " ['(1995)'],\n",
       " ['(1994)'],\n",
       " ['(1994)'],\n",
       " ['(1988)'],\n",
       " ['(1988)'],\n",
       " ['(1985)'],\n",
       " ['(1979)'],\n",
       " ['(1979)'],\n",
       " ['(1968)'],\n",
       " ['(1960)'],\n",
       " ['(1954)'],\n",
       " ['(1942)'],\n",
       " ['(1936)'],\n",
       " ['(1931)'],\n",
       " ['(2018)'],\n",
       " ['(I)', '(2019)'],\n",
       " ['(2016)'],\n",
       " ['(2018)'],\n",
       " ['(2019)'],\n",
       " ['(2018)'],\n",
       " ['(I)', '(2017)'],\n",
       " ['(2012)'],\n",
       " ['(2012)'],\n",
       " ['(2009)'],\n",
       " ['(2008)'],\n",
       " ['(2006)'],\n",
       " ['(2003)'],\n",
       " ['(2000)'],\n",
       " ['(1999)'],\n",
       " ['(1997)'],\n",
       " ['(1995)'],\n",
       " ['(1985)'],\n",
       " ['(1986)'],\n",
       " ['(1984)'],\n",
       " ['(1981)'],\n",
       " ['(1981)'],\n",
       " ['(1980)'],\n",
       " ['(1963)'],\n",
       " ['(1964)'],\n",
       " ['(1957)'],\n",
       " ['(1957)'],\n",
       " ['(1950)'],\n",
       " ['(1940)'],\n",
       " ['(2012)'],\n",
       " ['(2010)'],\n",
       " ['(2009)'],\n",
       " ['(2004)'],\n",
       " ['(2000)'],\n",
       " ['(1997)'],\n",
       " ['(1995)'],\n",
       " ['(1992)'],\n",
       " ['(1984)'],\n",
       " ['(1983)'],\n",
       " ['(1968)'],\n",
       " ['(1962)'],\n",
       " ['(1959)'],\n",
       " ['(1958)'],\n",
       " ['(1952)'],\n",
       " ['(1941)'],\n",
       " ['(1931)']]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup2.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text.split())\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "73e29e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9.3'],\n",
       " ['9.2'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['8.9'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5']]"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in soup.find_all('div',class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rating.append(i.text.split())\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "fc8322aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9.3'],\n",
       " ['9.2'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['9.0'],\n",
       " ['8.9'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.8'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.7'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.6'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.5'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3']]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup2.find_all('div',class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rating.append(i.text.split())\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "402aaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "fa676cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'name':top100,'YearOfRelease':year,'Rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "58eac3a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The, Shawshank, Redemption]</td>\n",
       "      <td>[(1994)]</td>\n",
       "      <td>[9.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, Godfather]</td>\n",
       "      <td>[(1972)]</td>\n",
       "      <td>[9.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Dark, Knight]</td>\n",
       "      <td>[(2008)]</td>\n",
       "      <td>[9.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, Lord, of, the, Rings:, The, Return, of, ...</td>\n",
       "      <td>[(2003)]</td>\n",
       "      <td>[9.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Schindler's, List]</td>\n",
       "      <td>[(1993)]</td>\n",
       "      <td>[9.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[North, by, Northwest]</td>\n",
       "      <td>[(1959)]</td>\n",
       "      <td>[8.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Vertigo]</td>\n",
       "      <td>[(1958)]</td>\n",
       "      <td>[8.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Singin', in, the, Rain]</td>\n",
       "      <td>[(1952)]</td>\n",
       "      <td>[8.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Citizen, Kane]</td>\n",
       "      <td>[(1941)]</td>\n",
       "      <td>[8.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[M, -, Eine, Stadt, sucht, einen, Mörder]</td>\n",
       "      <td>[(1931)]</td>\n",
       "      <td>[8.3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name YearOfRelease Rating\n",
       "0                        [The, Shawshank, Redemption]      [(1994)]  [9.3]\n",
       "1                                    [The, Godfather]      [(1972)]  [9.2]\n",
       "2                                 [The, Dark, Knight]      [(2008)]  [9.0]\n",
       "3   [The, Lord, of, the, Rings:, The, Return, of, ...      [(2003)]  [9.0]\n",
       "4                                 [Schindler's, List]      [(1993)]  [9.0]\n",
       "..                                                ...           ...    ...\n",
       "95                             [North, by, Northwest]      [(1959)]  [8.3]\n",
       "96                                          [Vertigo]      [(1958)]  [8.3]\n",
       "97                           [Singin', in, the, Rain]      [(1952)]  [8.3]\n",
       "98                                    [Citizen, Kane]      [(1941)]  [8.3]\n",
       "99          [M, -, Eine, Stadt, sucht, einen, Mörder]      [(1931)]  [8.3]\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ff6e9",
   "metadata": {},
   "source": [
    "Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "6494c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "72273ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make a list of all the movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "16cd8ea7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rocketry:', 'The', 'Nambi', 'Effect'],\n",
       " ['Anbe', 'Sivam'],\n",
       " ['Golmaal'],\n",
       " ['Jai', 'Bhim'],\n",
       " ['Nayakan'],\n",
       " ['Pariyerum', 'Perumal'],\n",
       " ['3', 'Idiots'],\n",
       " ['Apur', 'Sansar'],\n",
       " ['Manichitrathazhu'],\n",
       " ['Kumbalangi', 'Nights'],\n",
       " ['Black', 'Friday'],\n",
       " ['Taare', 'Zameen', 'Par'],\n",
       " ['C/o', 'Kancharapalem'],\n",
       " ['#Home'],\n",
       " ['Soorarai', 'Pottru'],\n",
       " ['Dangal'],\n",
       " ['Kireedam'],\n",
       " ['Kaithi'],\n",
       " ['Jersey'],\n",
       " ['Asuran'],\n",
       " ['96'],\n",
       " ['Thevar', 'Magan'],\n",
       " ['Visaaranai'],\n",
       " ['Pather', 'Panchali'],\n",
       " ['Thalapathi'],\n",
       " ['Sarpatta', 'Parambarai'],\n",
       " ['Natsamrat'],\n",
       " ['Drishyam', '2'],\n",
       " ['Thani', 'Oruvan'],\n",
       " ['Sardar', 'Udham'],\n",
       " ['Aparajito'],\n",
       " ['Vada', 'Chennai'],\n",
       " ['Jaane', 'Bhi', 'Do', 'Yaaro'],\n",
       " ['Khosla', 'Ka', 'Ghosla!'],\n",
       " ['777', 'Charlie'],\n",
       " ['Vikram'],\n",
       " ['Drishyam'],\n",
       " ['Chupke', 'Chupke'],\n",
       " ['Peranbu'],\n",
       " ['Agent', 'Sai', 'Srinivasa', 'Athreya'],\n",
       " ['Anniyan'],\n",
       " ['Mahanati'],\n",
       " ['Bangalore', 'Days'],\n",
       " ['Satya'],\n",
       " ['Super', 'Deluxe'],\n",
       " ['Premam'],\n",
       " ['Ratsasan'],\n",
       " ['Gangs', 'of', 'Wasseypur'],\n",
       " ['Devasuram'],\n",
       " ['Bhaag', 'Milkha', 'Bhaag'],\n",
       " ['Andhadhun'],\n",
       " ['Aruvi'],\n",
       " ['Drishyam'],\n",
       " ['Kannathil', 'Muthamittal'],\n",
       " ['Guide'],\n",
       " ['Chithram'],\n",
       " ['Shahid'],\n",
       " ['Vikram', 'Vedha'],\n",
       " ['Iruvar'],\n",
       " ['Sairat'],\n",
       " ['Zindagi', 'Na', 'Milegi', 'Dobara'],\n",
       " ['Paan', 'Singh', 'Tomar'],\n",
       " ['Tumbbad'],\n",
       " ['Mudhalvan'],\n",
       " ['Chhichhore'],\n",
       " ['Dhuruvangal', 'Pathinaaru'],\n",
       " ['Spadikam'],\n",
       " ['Swades:', 'We,', 'the', 'People'],\n",
       " ['Black'],\n",
       " ['Chak', 'De!', 'India'],\n",
       " ['Jo', 'Jeeta', 'Wohi', 'Sikandar'],\n",
       " ['Papanasam'],\n",
       " ['Pudhu', 'Pettai'],\n",
       " ['Mandela'],\n",
       " ['Pyaasa'],\n",
       " ['Munna', 'Bhai', 'M.B.B.S.'],\n",
       " ['PK'],\n",
       " ['Article', '15'],\n",
       " ['Soodhu', 'Kavvum'],\n",
       " ['Uri:', 'The', 'Surgical', 'Strike'],\n",
       " ['Queen'],\n",
       " ['Kaakkaa', 'Muttai'],\n",
       " ['Talvar'],\n",
       " ['Lagaan:', 'Once', 'Upon', 'a', 'Time', 'in', 'India'],\n",
       " ['OMG:', 'Oh', 'My', 'God!'],\n",
       " ['Jigarthanda'],\n",
       " ['Sarfarosh'],\n",
       " ['Udaan'],\n",
       " ['Barfi!'],\n",
       " ['Theeran', 'Adhigaaram', 'Ondru'],\n",
       " ['Sholay'],\n",
       " ['Hera', 'Pheri'],\n",
       " ['Ustad', 'Hotel'],\n",
       " ['The', 'Legend', 'of', 'Bhagat', 'Singh'],\n",
       " ['Angoor'],\n",
       " ['Rang', 'De', 'Basanti'],\n",
       " ['Baasha'],\n",
       " ['Baahubali', '2:', 'The', 'Conclusion'],\n",
       " ['Masaan'],\n",
       " ['Kahaani'],\n",
       " ['Dil', 'Chahta', 'Hai'],\n",
       " ['Maheshinte', 'Prathikaaram'],\n",
       " ['Virumandi'],\n",
       " ['A', 'Wednesday'],\n",
       " ['Roja'],\n",
       " ['Iqbal'],\n",
       " ['Nil', 'Battey', 'Sannata'],\n",
       " ['Pink'],\n",
       " ['Kaun', 'Pravin', 'Tambe?'],\n",
       " ['Pithamagan'],\n",
       " ['Lage', 'Raho', 'Munna', 'Bhai'],\n",
       " ['Shershaah'],\n",
       " ['Charulata'],\n",
       " ['Anand'],\n",
       " ['Section', '375'],\n",
       " ['Alai', 'Payuthey'],\n",
       " ['Jana', 'Gana', 'Mana'],\n",
       " ['Bajrangi', 'Bhaijaan'],\n",
       " ['Omkara'],\n",
       " ['Lucia'],\n",
       " ['Bombay'],\n",
       " ['Oru', 'Vadakkan', 'Veeragatha'],\n",
       " ['Bommarillu'],\n",
       " ['K.G.F:', 'Chapter', '2'],\n",
       " ['Indian'],\n",
       " ['K.G.F:', 'Chapter', '1'],\n",
       " ['The', 'Great', 'Indian', 'Kitchen'],\n",
       " ['Haider'],\n",
       " ['Rangasthalam'],\n",
       " ['Mughal-E-Azam'],\n",
       " ['Dilwale', 'Dulhania', 'Le', 'Jayenge'],\n",
       " ['Special', 'Chabbis'],\n",
       " ['Maqbool'],\n",
       " ['Athadu'],\n",
       " ['Andaz', 'Apna', 'Apna'],\n",
       " ['Thadam'],\n",
       " ['Maanaadu'],\n",
       " ['Padayappa'],\n",
       " ['Pelli', 'Choopulu'],\n",
       " ['Vaaranam', 'Aayiram'],\n",
       " ['Android', 'Kunjappan', 'Version', '5.25'],\n",
       " ['Gulaal'],\n",
       " ['Naduvula', 'Konjam', 'Pakkatha', 'Kaanom'],\n",
       " ['Gully', 'Boy'],\n",
       " ['Ugly'],\n",
       " ['Deewaar'],\n",
       " ['Badhaai', 'ho'],\n",
       " ['Vaastav:', 'The', 'Reality'],\n",
       " ['Evaru'],\n",
       " ['Company'],\n",
       " ['Ulidavaru', 'Kandanthe'],\n",
       " ['Kshanam'],\n",
       " ['Padosan'],\n",
       " ['Aadukalam'],\n",
       " ['Maanagaram'],\n",
       " ['Nayattu'],\n",
       " ['Thondimuthalum', 'Dhriksakshiyum'],\n",
       " ['Dev.D'],\n",
       " ['My', 'Name', 'Is', 'Khan'],\n",
       " ['Major'],\n",
       " ['Pranchiyettan', 'and', 'the', 'Saint'],\n",
       " ['Take', 'Off'],\n",
       " ['Baishe', 'Srabon'],\n",
       " ['Kal', 'Ho', 'Naa', 'Ho'],\n",
       " ['Jab', 'We', 'Met'],\n",
       " ['Arjun', 'Reddy'],\n",
       " ['Manjhi:', 'The', 'Mountain', 'Man'],\n",
       " ['Ayyappanum', 'Koshiyum'],\n",
       " ['Super', '30'],\n",
       " ['Dil', 'Bechara'],\n",
       " ['Mukkabaaz'],\n",
       " ['Karnan'],\n",
       " ['Border'],\n",
       " ['Deiva', 'Thirumagal'],\n",
       " ['Ship', 'of', 'Theseus'],\n",
       " ['Jalsaghar'],\n",
       " ['Charlie'],\n",
       " ['Vedam'],\n",
       " ['Padman'],\n",
       " ['Salaam', 'Bombay!'],\n",
       " ['RRR', '(Rise', 'Roar', 'Revolt)'],\n",
       " ['Bãhubali:', 'The', 'Beginning'],\n",
       " ['Ankhon', 'Dekhi'],\n",
       " ['Baby'],\n",
       " ['Malik'],\n",
       " ['Vinnaithaandi', 'Varuvaayaa'],\n",
       " ['Pizza'],\n",
       " ['M.S.', 'Dhoni:', 'The', 'Untold', 'Story'],\n",
       " ['Kirik', 'Party'],\n",
       " ['English', 'Vinglish'],\n",
       " ['Hindi', 'Medium'],\n",
       " ['Lakshya'],\n",
       " ['Memories'],\n",
       " ['Dor'],\n",
       " ['Airlift'],\n",
       " ['Johnny', 'Gaddaar'],\n",
       " ['Hey', 'Ram'],\n",
       " ['Joseph'],\n",
       " ['Kaakha..Kaakha:', 'The', 'Police'],\n",
       " ['The', 'Tashkent', 'Files'],\n",
       " ['Hridayam'],\n",
       " ['Gangaajal'],\n",
       " ['Anjaam', 'Pathiraa'],\n",
       " ['Vettaiyaadu', 'Vilaiyaadu'],\n",
       " ['Mumbai', 'Police'],\n",
       " ['The', 'Lunchbox'],\n",
       " ['Ab', 'Tak', 'Chhappan'],\n",
       " ['Okkadu'],\n",
       " ['Unnaipol', 'Oruvan'],\n",
       " ['Secret', 'Superstar'],\n",
       " ['Pokiri'],\n",
       " ['Angamaly', 'Diaries'],\n",
       " ['Thuppakki'],\n",
       " ['Oopiri'],\n",
       " ['Manam'],\n",
       " ['Vicky', 'Donor'],\n",
       " ['Mother', 'India'],\n",
       " ['Ghilli'],\n",
       " ['RangiTaranga'],\n",
       " ['Veer-Zaara'],\n",
       " ['Stanley', 'Ka', 'Dabba'],\n",
       " ['Mimi'],\n",
       " ['Kaththi'],\n",
       " ['Udta', 'Punjab'],\n",
       " ['Rock', 'On!!'],\n",
       " ['Nayak:', 'The', 'Real', 'Hero'],\n",
       " ['Mr.', 'India'],\n",
       " ['Dia'],\n",
       " ['Badla'],\n",
       " ['Happy', 'Days'],\n",
       " ['Raazi'],\n",
       " ['Sonchiriya'],\n",
       " ['Minnal', 'Murali'],\n",
       " ['Thulladha', 'Manamum', 'Thullum'],\n",
       " ['Dasvidaniya'],\n",
       " ['Aayirathil', 'Oruvan'],\n",
       " ['Poove', 'Unakkaga'],\n",
       " ['Kai', 'po', 'che!'],\n",
       " ['Joji'],\n",
       " ['Goodachari'],\n",
       " ['Ko'],\n",
       " ['Don'],\n",
       " ['Aligarh'],\n",
       " ['Ennu', 'Ninte', 'Moideen'],\n",
       " ['Guru'],\n",
       " ['24'],\n",
       " ['Velaiilla', 'Pattadhari'],\n",
       " ['Kapoor', '&', 'Sons'],\n",
       " ['Colour', 'Photo'],\n",
       " ['Rockstar']]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    name.append(i.text.split()[1:-1])\n",
    "name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "c3b594f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del name[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "c06d9a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "591f8fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kahaani']"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "b250278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make a list of all the movie year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "bd5faeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(2022)'],\n",
       " ['(2003)'],\n",
       " ['(1979)'],\n",
       " ['(2021)'],\n",
       " ['(1987)'],\n",
       " ['(2018)'],\n",
       " ['(2009)'],\n",
       " ['(1959)'],\n",
       " ['(1993)'],\n",
       " ['(2019)'],\n",
       " ['(2004)'],\n",
       " ['(2007)'],\n",
       " ['(2018)'],\n",
       " ['(2021)'],\n",
       " ['(2020)'],\n",
       " ['(2016)'],\n",
       " ['(1989)'],\n",
       " ['(2019)'],\n",
       " ['(2019)'],\n",
       " ['(2019)'],\n",
       " ['(2018)'],\n",
       " ['(1992)'],\n",
       " ['(2015)'],\n",
       " ['(1955)'],\n",
       " ['(1991)'],\n",
       " ['(2021)'],\n",
       " ['(2016)'],\n",
       " ['(2021)'],\n",
       " ['(2015)'],\n",
       " ['(2021)'],\n",
       " ['(1956)'],\n",
       " ['(2018)'],\n",
       " ['(1983)'],\n",
       " ['(2006)'],\n",
       " ['(2022)'],\n",
       " ['(2022)'],\n",
       " ['(2013)'],\n",
       " ['(1975)'],\n",
       " ['(2018)'],\n",
       " ['(2019)'],\n",
       " ['(2005)'],\n",
       " ['(2018)'],\n",
       " ['(2014)'],\n",
       " ['(1998)'],\n",
       " ['(2019)'],\n",
       " ['(2015)'],\n",
       " ['(2018)'],\n",
       " ['(2012)'],\n",
       " ['(1993)'],\n",
       " ['(2013)'],\n",
       " ['(2018)'],\n",
       " ['(2016)'],\n",
       " ['(2015)'],\n",
       " ['(2002)'],\n",
       " ['(1965)'],\n",
       " ['(1988)'],\n",
       " ['(2012)'],\n",
       " ['(2017)'],\n",
       " ['(1997)'],\n",
       " ['(2016)'],\n",
       " ['(2011)'],\n",
       " ['(2012)'],\n",
       " ['(2018)'],\n",
       " ['(1999)'],\n",
       " ['(2019)'],\n",
       " ['(2016)'],\n",
       " ['(1995)'],\n",
       " ['(2004)'],\n",
       " ['(2005)'],\n",
       " ['(2007)'],\n",
       " ['(1992)'],\n",
       " ['(2015)'],\n",
       " ['(2006)'],\n",
       " ['(2021)'],\n",
       " ['(1957)'],\n",
       " ['(2003)'],\n",
       " ['(2014)'],\n",
       " ['(2019)'],\n",
       " ['(2013)'],\n",
       " ['(2019)'],\n",
       " ['(2013)'],\n",
       " ['(2014)'],\n",
       " ['(2015)'],\n",
       " ['(2001)'],\n",
       " ['(2012)'],\n",
       " ['(2014)'],\n",
       " ['(1999)'],\n",
       " ['(2010)'],\n",
       " ['(2012)'],\n",
       " ['(2017)'],\n",
       " ['(1975)'],\n",
       " ['(2000)'],\n",
       " ['(2012)'],\n",
       " ['(2002)'],\n",
       " ['(1982)'],\n",
       " ['(2006)'],\n",
       " ['(1995)'],\n",
       " ['(2017)'],\n",
       " ['(2015)'],\n",
       " ['(2012)']]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    year.append(i.text.split())\n",
    "del year[100:]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "2965b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "760b8a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8.5'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.4'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.3'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.2'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.1'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0'],\n",
       " ['8.0']]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rate.append(i.text.split())\n",
    "del rate[100:]\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "6e4c7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rate),len(year),len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "d9158f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'Title':name,'YearOfRelease':year,'Rating':rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "7ca6ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Rocketry:, The, Nambi, Effect]</td>\n",
       "      <td>[(2022)]</td>\n",
       "      <td>[8.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Anbe, Sivam]</td>\n",
       "      <td>[(2003)]</td>\n",
       "      <td>[8.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Golmaal]</td>\n",
       "      <td>[(1979)]</td>\n",
       "      <td>[8.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Jai, Bhim]</td>\n",
       "      <td>[(2021)]</td>\n",
       "      <td>[8.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Nayakan]</td>\n",
       "      <td>[(1987)]</td>\n",
       "      <td>[8.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Rang, De, Basanti]</td>\n",
       "      <td>[(2006)]</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Baasha]</td>\n",
       "      <td>[(1995)]</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Baahubali, 2:, The, Conclusion]</td>\n",
       "      <td>[(2017)]</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Masaan]</td>\n",
       "      <td>[(2015)]</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[Kahaani]</td>\n",
       "      <td>[(2012)]</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title YearOfRelease Rating\n",
       "0    [Rocketry:, The, Nambi, Effect]      [(2022)]  [8.5]\n",
       "1                      [Anbe, Sivam]      [(2003)]  [8.4]\n",
       "2                          [Golmaal]      [(1979)]  [8.4]\n",
       "3                        [Jai, Bhim]      [(2021)]  [8.4]\n",
       "4                          [Nayakan]      [(1987)]  [8.4]\n",
       "..                               ...           ...    ...\n",
       "95               [Rang, De, Basanti]      [(2006)]  [8.0]\n",
       "96                          [Baasha]      [(1995)]  [8.0]\n",
       "97  [Baahubali, 2:, The, Conclusion]      [(2017)]  [8.0]\n",
       "98                          [Masaan]      [(2015)]  [8.0]\n",
       "99                         [Kahaani]      [(2012)]  [8.0]\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a3235",
   "metadata": {},
   "source": [
    "Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d55b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#program to display the list of respected former presidents of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "65802768",
   "metadata": {},
   "outputs": [],
   "source": [
    "page4=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup4=BeautifulSoup(page4.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "2df28d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Shri',\n",
       "  'Ram',\n",
       "  'Nath',\n",
       "  'Kovind',\n",
       "  '(birth',\n",
       "  '-',\n",
       "  '1945)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2017',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2022'],\n",
       " ['Shri',\n",
       "  'Pranab',\n",
       "  'Mukherjee',\n",
       "  '(1935-2020)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2012',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2017'],\n",
       " ['Smt',\n",
       "  'Pratibha',\n",
       "  'Devisingh',\n",
       "  'Patil',\n",
       "  '(birth',\n",
       "  '-',\n",
       "  '1934)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2007',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2012'],\n",
       " ['DR.',\n",
       "  'A.P.J.',\n",
       "  'Abdul',\n",
       "  'Kalam',\n",
       "  '(1931-2015)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2002',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '2007'],\n",
       " ['Shri',\n",
       "  'K.',\n",
       "  'R.',\n",
       "  'Narayanan',\n",
       "  '(1920',\n",
       "  '-',\n",
       "  '2005)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '1997',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,'],\n",
       " ['Dr',\n",
       "  'Shankar',\n",
       "  'Dayal',\n",
       "  'Sharma',\n",
       "  '(1918-1999)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '1992',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,'],\n",
       " ['Shri',\n",
       "  'R',\n",
       "  'Venkataraman',\n",
       "  '(1910-2009)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '1987',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,'],\n",
       " ['Giani',\n",
       "  'Zail',\n",
       "  'Singh',\n",
       "  '(1916-1994)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '1982',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,'],\n",
       " ['Shri',\n",
       "  'Neelam',\n",
       "  'Sanjiva',\n",
       "  'Reddy',\n",
       "  '(1913-1996)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '25',\n",
       "  'July,',\n",
       "  '1977',\n",
       "  'to',\n",
       "  '25',\n",
       "  'July,'],\n",
       " ['Dr.',\n",
       "  'Fakhruddin',\n",
       "  'Ali',\n",
       "  'Ahmed',\n",
       "  '(1905-1977)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '24',\n",
       "  'August,',\n",
       "  '1974',\n",
       "  'to',\n",
       "  '11',\n",
       "  'February,'],\n",
       " ['Shri',\n",
       "  'Varahagiri',\n",
       "  'Venkata',\n",
       "  'Giri',\n",
       "  '(1894-1980)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '3',\n",
       "  'May,',\n",
       "  '1969',\n",
       "  'to',\n",
       "  '20',\n",
       "  'July,',\n",
       "  '1969',\n",
       "  'and',\n",
       "  '24',\n",
       "  'August,',\n",
       "  '1969',\n",
       "  'to',\n",
       "  '24',\n",
       "  'August,'],\n",
       " ['Dr.',\n",
       "  'Zakir',\n",
       "  'Husain',\n",
       "  '(1897-1969)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '13',\n",
       "  'May,',\n",
       "  '1967',\n",
       "  'to',\n",
       "  '3',\n",
       "  'May,'],\n",
       " ['Dr.',\n",
       "  'Sarvepalli',\n",
       "  'Radhakrishnan',\n",
       "  '(1888-1975)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '13',\n",
       "  'May,',\n",
       "  '1962',\n",
       "  'to',\n",
       "  '13',\n",
       "  'May,'],\n",
       " ['Dr.',\n",
       "  'Rajendra',\n",
       "  'Prasad',\n",
       "  '(1884-1963)',\n",
       "  'Term',\n",
       "  'of',\n",
       "  'Office:',\n",
       "  '26',\n",
       "  'January,',\n",
       "  '1950',\n",
       "  'to',\n",
       "  '13',\n",
       "  'May,']]"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in soup4.find_all('div',class_=\"presidentListing\"):\n",
    "    name.append(i.text.split()[0:-1])\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aaa6c8",
   "metadata": {},
   "source": [
    "Question 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453336e",
   "metadata": {},
   "source": [
    "a)top 10 ODI teams in Men's cricket with matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7630e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5a=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup5a=BeautifulSoup(page5a.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4ab181db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'India',\n",
       " 'Pakistan',\n",
       " 'Australia',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "for i in soup5a.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "del team[10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7992b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15', '27', '28', '19', '23', '21', '27', '29', '38', '18']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches=[]\n",
    "m=soup5a.find('td',class_=\"rankings-block__banner--matches\")\n",
    "matches.append(m.text)\n",
    "for i in soup5a.find_all('tr',class_=\"table-body\"):\n",
    "    matches.append(i.text.split()[-3])\n",
    "del matches[10:]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8d61b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "points=[]\n",
    "i=soup5a.find('td',class_=\"rankings-block__banner--points\")\n",
    "points.append(i.text)\n",
    "for i in soup5a.find_all('tr',class_=\"table-body\"):\n",
    "    points.append(i.text.split()[-2])\n",
    "del points[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "24994c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['128'],\n",
       " ['119'],\n",
       " ['110'],\n",
       " ['106'],\n",
       " ['101'],\n",
       " ['101'],\n",
       " ['98'],\n",
       " ['92'],\n",
       " ['69'],\n",
       " ['69']]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamratings=[]\n",
    "a=soup5a.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "teamratings.append(a.text.split())\n",
    "for i in soup5a.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    teamratings.append(i.text.split())\n",
    "\n",
    "del teamratings[10:]\n",
    "teamratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "341a3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmensteam=pd.DataFrame({'Name':team,'Matches':matches,'Points':points,'TeamRating':teamratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "69c20c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>TeamRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>15</td>\n",
       "      <td>1,913</td>\n",
       "      <td>[128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>[119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,965</td>\n",
       "      <td>[110]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>[106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,639</td>\n",
       "      <td>[98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>37</td>\n",
       "      <td>2,562</td>\n",
       "      <td>[69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>[69]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Matches Points TeamRating\n",
       "0   New Zealand      15  1,913      [128]\n",
       "1       England      27  3,226      [119]\n",
       "2         India      27  2,965      [110]\n",
       "3      Pakistan      19  2,005      [106]\n",
       "4     Australia      23  2,325      [101]\n",
       "5  South Africa      21  2,111      [101]\n",
       "6    Bangladesh      27  2,639       [98]\n",
       "7     Sri Lanka      29  2,658       [92]\n",
       "8   West Indies      37  2,562       [69]\n",
       "9   Afghanistan      18  1,238       [69]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmensteam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f0023",
   "metadata": {},
   "source": [
    "Question 5B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77376b",
   "metadata": {},
   "source": [
    "b)top 10 ODI batsman in Men's cricket along with their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "71efbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5b=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup5b=BeautifulSoup(page5b.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "acfde987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " ['Imam-ul-Haq'],\n",
       " ['Rassie', 'van', 'der', 'Dussen'],\n",
       " ['Quinton', 'de', 'Kock'],\n",
       " ['Virat', 'Kohli'],\n",
       " ['Rohit', 'Sharma'],\n",
       " ['Ross', 'Taylor'],\n",
       " ['David', 'Warner'],\n",
       " ['Jonny', 'Bairstow'],\n",
       " ['Aaron', 'Finch']]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player=[]\n",
    "player1=soup5b.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "player.append(player1.text)\n",
    "for i in soup5b.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split())\n",
    "del player[10:]\n",
    "player\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "68a7238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PAK'],\n",
       " ['PAK'],\n",
       " ['SA'],\n",
       " ['SA'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['ENG'],\n",
       " ['AUS']]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "t1=soup5b.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "team.append(t1.text.split())\n",
    "team\n",
    "for i in soup5b.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.split())\n",
    "del team [10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f474ae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['892'],\n",
       " ['815'],\n",
       " ['789'],\n",
       " ['784'],\n",
       " ['774'],\n",
       " ['770'],\n",
       " ['752'],\n",
       " ['737'],\n",
       " ['732'],\n",
       " ['715']]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "r=soup5b.find('div',class_=\"rankings-block__banner--rating\")\n",
    "rating.append(r.text.split())\n",
    "for i in soup5b.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.split())\n",
    "del rating [10:]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "bfcbbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_odibatsman=pd.DataFrame({'Name of the player':player,'Team':team,'Rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "1d5f5f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Imam-ul-Haq]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rassie, van, der, Dussen]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Quinton, de, Kock]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[784]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Virat, Kohli]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Rohit, Sharma]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[770]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Ross, Taylor]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[752]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[David, Warner]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Jonny, Bairstow]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Aaron, Finch]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[715]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name of the player   Team Rating\n",
       "0                  Babar Azam  [PAK]  [892]\n",
       "1               [Imam-ul-Haq]  [PAK]  [815]\n",
       "2  [Rassie, van, der, Dussen]   [SA]  [789]\n",
       "3         [Quinton, de, Kock]   [SA]  [784]\n",
       "4              [Virat, Kohli]  [IND]  [774]\n",
       "5             [Rohit, Sharma]  [IND]  [770]\n",
       "6              [Ross, Taylor]   [NZ]  [752]\n",
       "7             [David, Warner]  [AUS]  [737]\n",
       "8           [Jonny, Bairstow]  [ENG]  [732]\n",
       "9              [Aaron, Finch]  [AUS]  [715]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_odibatsman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf735ef",
   "metadata": {},
   "source": [
    "c)top 10 ODI bowlers in Men's cricket along with their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ff907eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5c=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup5c=BeautifulSoup(page5c.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "896255db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Trent', 'Boult'],\n",
       " ['Jasprit', 'Bumrah'],\n",
       " ['Shaheen', 'Afridi'],\n",
       " ['Josh', 'Hazlewood'],\n",
       " ['Mujeeb', 'Ur', 'Rahman'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Matt', 'Henry'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Chris', 'Woakes']]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler=[]\n",
    "b=soup5c.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "bowler.append(b.text.split())\n",
    "for i in soup5c.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "  bowler.append(i.text.split())  \n",
    "del bowler[10:]\n",
    "bowler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ade14300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NZ'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['BAN'],\n",
       " ['NZ'],\n",
       " ['AFG'],\n",
       " ['AFG'],\n",
       " ['ENG']]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "t=soup5c.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "team.append(t.text.split())\n",
    "\n",
    "for i in soup5c.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.split())\n",
    "del team[10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2edea0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['704'],\n",
       " ['689'],\n",
       " ['681'],\n",
       " ['679'],\n",
       " ['676'],\n",
       " ['672'],\n",
       " ['670'],\n",
       " ['657'],\n",
       " ['651'],\n",
       " ['640']]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "r2=soup5c.find('div',class_=\"rankings-block__banner--rating\")\n",
    "rating.append(r2.text.split())\n",
    "for i in soup5c.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.split())\n",
    "del rating[10:]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "49c3658e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Trent, Boult]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[704]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Jasprit, Bumrah]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[681]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[672]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Matt, Henry]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[670]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[657]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Chris, Woakes]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[640]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name of the player   Team Rating\n",
       "0        [Trent, Boult]   [NZ]  [704]\n",
       "1     [Jasprit, Bumrah]  [IND]  [689]\n",
       "2     [Shaheen, Afridi]  [PAK]  [681]\n",
       "3     [Josh, Hazlewood]  [AUS]  [679]\n",
       "4  [Mujeeb, Ur, Rahman]  [AFG]  [676]\n",
       "5       [Mehedi, Hasan]  [BAN]  [672]\n",
       "6         [Matt, Henry]   [NZ]  [670]\n",
       "7      [Mohammad, Nabi]  [AFG]  [657]\n",
       "8        [Rashid, Khan]  [AFG]  [651]\n",
       "9       [Chris, Woakes]  [ENG]  [640]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_odibowlers=pd.DataFrame({'Name of the player':bowler,'Team':team,'Rating':rating})\n",
    "df_odibowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66493163",
   "metadata": {},
   "source": [
    "Question 6a:top 10 ODI teams in Women's cricket with matches, points and rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "9658b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page6a=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup6a=BeautifulSoup(page6a.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "24e4b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Pakistan',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "for i in soup6a.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "del team[10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "d27088ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4,837',\n",
       " '4,046',\n",
       " '4,157',\n",
       " '3,219',\n",
       " '3,019',\n",
       " '2,768',\n",
       " '930',\n",
       " '1,962',\n",
       " '495',\n",
       " '351']"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points=[]\n",
    "i=soup6a.find('td',class_=\"rankings-block__banner--points\")\n",
    "points.append(i.text)\n",
    "for i in soup6a.find_all('tr',class_=\"table-body\"):\n",
    "    points.append(i.text.split()[-2])\n",
    "del points[10:]\n",
    "points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "141b8039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['167'],\n",
       " ['123'],\n",
       " ['119'],\n",
       " ['101'],\n",
       " ['97'],\n",
       " ['92'],\n",
       " ['78'],\n",
       " ['65'],\n",
       " ['45'],\n",
       " ['44']]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamratings=[]\n",
    "a=soup6a.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "teamratings.append(a.text.split())\n",
    "for i in soup6a.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    teamratings.append(i.text.split())\n",
    "del teamratings[10:]\n",
    "teamratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "0e04b56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '33', '35', '32', '31', '30', '12', '30', '11', '8']"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches=[]\n",
    "m=soup6a.find('td',class_=\"rankings-block__banner--matches\")\n",
    "matches.append(m.text)\n",
    "for i in soup6a.find_all('tr',class_=\"table-body\"):\n",
    "    matches.append(i.text.split()[-3])\n",
    "del matches[10:]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "434b6e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>TeamRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>[167]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>[123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>[119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>[97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>[78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>[65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>[45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>[44]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Matches Points TeamRating\n",
       "0     Australia      29  4,837      [167]\n",
       "1       England      33  4,046      [123]\n",
       "2  South Africa      35  4,157      [119]\n",
       "3         India      32  3,219      [101]\n",
       "4   New Zealand      31  3,019       [97]\n",
       "5   West Indies      30  2,768       [92]\n",
       "6    Bangladesh      12    930       [78]\n",
       "7      Pakistan      30  1,962       [65]\n",
       "8     Sri Lanka      11    495       [45]\n",
       "9       Ireland       8    351       [44]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwomensteam=pd.DataFrame({'Name':team,'Matches':matches,'Points':points,'TeamRating':teamratings})\n",
    "dfwomensteam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e7be1",
   "metadata": {},
   "source": [
    "Question 6B:top 10 ODI batsman in Women's cricket along with their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "b59e3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page6b=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup6b=BeautifulSoup(page6b.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "0abdb305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy',\n",
       " ['Beth', 'Mooney'],\n",
       " ['Natalie', 'Sciver'],\n",
       " ['Laura', 'Wolvaardt'],\n",
       " ['Meg', 'Lanning'],\n",
       " ['Rachael', 'Haynes'],\n",
       " ['Amy', 'Satterthwaite'],\n",
       " ['Tammy', 'Beaumont'],\n",
       " ['Chamari', 'Athapaththu'],\n",
       " ['Smriti', 'Mandhana']]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player=[]\n",
    "player1=soup6b.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "player.append(player1.text)\n",
    "for i in soup6b.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split())\n",
    "del player[10:]\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "32145a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AUS'],\n",
       " ['AUS'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['NZ'],\n",
       " ['ENG'],\n",
       " ['SL'],\n",
       " ['IND']]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "t1=soup6b.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "team.append(t1.text.split())\n",
    "team\n",
    "for i in soup6b.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.split())\n",
    "del team [10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "61943555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['785'],\n",
       " ['749'],\n",
       " ['747'],\n",
       " ['732'],\n",
       " ['710'],\n",
       " ['701'],\n",
       " ['681'],\n",
       " ['667'],\n",
       " ['655'],\n",
       " ['649']]"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "r=soup6b.find('div',class_=\"rankings-block__banner--rating\")\n",
    "rating.append(r.text.split())\n",
    "for i in soup6b.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.split())\n",
    "del rating [10:]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "3b7316b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beth, Mooney]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Natalie, Sciver]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Laura, Wolvaardt]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Meg, Lanning]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Rachael, Haynes]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Amy, Satterthwaite]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[681]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Tammy, Beaumont]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Chamari, Athapaththu]</td>\n",
       "      <td>[SL]</td>\n",
       "      <td>[655]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Smriti, Mandhana]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[649]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name of the player   Team Rating\n",
       "0            Alyssa Healy  [AUS]  [785]\n",
       "1          [Beth, Mooney]  [AUS]  [749]\n",
       "2       [Natalie, Sciver]  [ENG]  [747]\n",
       "3      [Laura, Wolvaardt]   [SA]  [732]\n",
       "4          [Meg, Lanning]  [AUS]  [710]\n",
       "5       [Rachael, Haynes]  [AUS]  [701]\n",
       "6    [Amy, Satterthwaite]   [NZ]  [681]\n",
       "7       [Tammy, Beaumont]  [ENG]  [667]\n",
       "8  [Chamari, Athapaththu]   [SL]  [655]\n",
       "9      [Smriti, Mandhana]  [IND]  [649]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_odiwomenbatsman=pd.DataFrame({'Name of the player':player,'Team':team,'Rating':rating})\n",
    "df_odiwomenbatsman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3556a3",
   "metadata": {},
   "source": [
    "c)top 10 ODI bowlers in Women's cricket along with their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "6c79253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page6c=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "soup6c=BeautifulSoup(page6c.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "25b19346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sophie', 'Ecclestone'],\n",
       " ['Jess', 'Jonassen'],\n",
       " ['Megan', 'Schutt'],\n",
       " ['Shabnim', 'Ismail'],\n",
       " ['Jhulan', 'Goswami'],\n",
       " ['Ayabonga', 'Khaka'],\n",
       " ['Rajeshwari', 'Gayakwad'],\n",
       " ['Hayley', 'Matthews'],\n",
       " ['Katherine', 'Brunt'],\n",
       " ['Marizanne', 'Kapp']]"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler=[]\n",
    "b=soup6c.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "bowler.append(b.text.split())\n",
    "for i in soup6c.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "  bowler.append(i.text.split())  \n",
    "del bowler[10:]\n",
    "bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "f3e522c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ENG'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['SA'],\n",
       " ['IND'],\n",
       " ['SA'],\n",
       " ['IND'],\n",
       " ['WI'],\n",
       " ['ENG'],\n",
       " ['SA']]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "t=soup6c.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "team.append(t.text.split())\n",
    "\n",
    "for i in soup6c.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.split())\n",
    "del team[10:]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "7be55c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['761'],\n",
       " ['725'],\n",
       " ['722'],\n",
       " ['722'],\n",
       " ['644'],\n",
       " ['634'],\n",
       " ['613'],\n",
       " ['612'],\n",
       " ['601'],\n",
       " ['598']]"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "r2=soup6c.find('div',class_=\"rankings-block__banner--rating\")\n",
    "rating.append(r2.text.split())\n",
    "for i in soup6c.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.split())\n",
    "del rating[10:]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "07b68397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sophie, Ecclestone]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[761]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Jess, Jonassen]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[725]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Megan, Schutt]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Shabnim, Ismail]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Jhulan, Goswami]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Ayabonga, Khaka]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[634]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Rajeshwari, Gayakwad]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Hayley, Matthews]</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Katherine, Brunt]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[601]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Marizanne, Kapp]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[598]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name of the player   Team Rating\n",
       "0    [Sophie, Ecclestone]  [ENG]  [761]\n",
       "1        [Jess, Jonassen]  [AUS]  [725]\n",
       "2         [Megan, Schutt]  [AUS]  [722]\n",
       "3       [Shabnim, Ismail]   [SA]  [722]\n",
       "4       [Jhulan, Goswami]  [IND]  [644]\n",
       "5       [Ayabonga, Khaka]   [SA]  [634]\n",
       "6  [Rajeshwari, Gayakwad]  [IND]  [613]\n",
       "7      [Hayley, Matthews]   [WI]  [612]\n",
       "8      [Katherine, Brunt]  [ENG]  [601]\n",
       "9       [Marizanne, Kapp]   [SA]  [598]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_odiwomenbowlers=pd.DataFrame({'Name of the player':bowler,'Team':team,'Rating':rating})\n",
    "df_odiwomenbowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac9484",
   "metadata": {},
   "source": [
    "Question 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "9b954c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 things to know before the stock market opens Friday',\n",
       " \"Britain's star-studded 'Wagatha Christie' libel trial is over: Here's what went down\",\n",
       " 'Susquehanna downgrades Roku citing near-term macro pressures',\n",
       " 'Stocks making the biggest moves in the premarket: Amazon, Roku, Intel and more',\n",
       " \"Analysts hail Amazon as a port in the storm after retail giant's strong quarter\",\n",
       " 'Chevron, Exxon post record quarterly profits as commodity prices boom',\n",
       " 'Higher prices help Procter & Gamble, but Tide maker warns of more challenges',\n",
       " \"Don't expect a sudden turnaround on supply chain problems, top autos CEO says\",\n",
       " \"Apple's iPhone sales are creating a strong 'moat' for tech giant, analysts say\",\n",
       " 'Bitcoin hits 6-week high topping $24,000 in a post-Fed rally ',\n",
       " 'Ukraine denies missile strike on Donbas prison; Wagner fighters given front-line duties, UK says ',\n",
       " 'Cold showers and more: German city turns off the hot water to survive gas cuts',\n",
       " 'China inches closer to getting alternative iron ore supply from Simandou   ',\n",
       " 'Euro zone grows 0.7% in the second quarter despite gas crisis, inflation surge',\n",
       " \"Apple's iPhones held up surprisingly well in China even as the country faced Covid lockdowns\",\n",
       " 'U.S. Treasury yields rise to end the week',\n",
       " 'Toxic culture and ‘race to the bottom’: Pilots on why air travel is in chaos',\n",
       " \"New Zealand's borders are fully reopening after more than two years\",\n",
       " 'European markets climb with earnings, economic data on the agenda',\n",
       " 'Dollar strength is more worrisome than inflation for Asia, economist says',\n",
       " 'Biden-Xi make plans to meet in person, official says — and China warns on Taiwan',\n",
       " \"China's Xi is expected to face challenges when he enters unprecedented third term\",\n",
       " 'Amazon says consumer spending remains strong, bucking broader retail gloom',\n",
       " \"'Churning out good cash': Analyst says a slowdown could boost these global stocks\",\n",
       " \"JPMorgan says buy the dip in growth names, which look 'more interesting' now\",\n",
       " \"Apple's services slowdown is potential concern for investors focused on profit margins\",\n",
       " 'Amazon hopped over a low bar this quarter and guided higher in tough environment',\n",
       " \"Hong Kong's Hang Seng drops more than 2% with tech stocks under pressure\",\n",
       " \"Apple's supply-constraints weren't as bad as it feared, leading to a strong quarter\",\n",
       " \"Cramer's lightning round: Marqeta is not a buy\"]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page7=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup7=BeautifulSoup(page7.content,'html.parser')\n",
    "headline=[]\n",
    "for i in soup7.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0046b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9c6e136e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13 Min Ago',\n",
       " '24 Min Ago',\n",
       " '49 Min Ago',\n",
       " '52 Min Ago',\n",
       " '57 Min Ago',\n",
       " '1 Hour Ago',\n",
       " '1 Hour Ago',\n",
       " '2 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '14 Hours Ago']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "for i in soup7.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "   time.append(i.text)\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b7d5b",
   "metadata": {},
   "source": [
    "len(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "44eee689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2022/07/29/5-things-to-know-before-the-stock-market-opens-friday-july-29.html',\n",
       " 'https://www.cnbc.com/2022/07/29/-rebekah-vardy-v-coleen-rooney-uk-wagatha-christie-libel-trial-is-over.html',\n",
       " 'https://www.cnbc.com/2022/07/29/susquehanna-downgrades-roku-citing-near-term-macro-pressure.html',\n",
       " 'https://www.cnbc.com/2022/07/29/stocks-making-the-biggest-moves-in-the-premarket-amazon-roku-intel-and-more.html',\n",
       " 'https://www.cnbc.com/2022/07/29/analysts-hail-amazon-as-a-port-in-the-storm-after-the-retail-giants-strong-quarter.html',\n",
       " 'https://www.cnbc.com/2022/07/29/exxon-xom-and-chevron-cvx-earnings-q2-2022.html',\n",
       " 'https://www.cnbc.com/2022/07/29/procter-gamble-pg-q4-2022-earnings.html',\n",
       " 'https://www.cnbc.com/2022/07/29/renault-dont-expect-a-sudden-turnaround-on-supply-chain-problems.html',\n",
       " 'https://www.cnbc.com/2022/07/29/apples-iphone-sales-creating-a-strong-moat-for-tech-giant-analysts.html',\n",
       " 'https://www.cnbc.com/2022/07/29/bitcoin-btc-price-rises-following-stocks-higher-in-a-post-fed-rally-.html',\n",
       " 'https://www.cnbc.com/2022/07/29/russia-ukraine-live-updates.html',\n",
       " 'https://www.cnbc.com/2022/07/29/hanover-bans-hot-showers-as-russian-gas-crisis-begins-to-bite.html',\n",
       " 'https://www.cnbc.com/2022/07/29/china-inches-closer-to-getting-alternative-iron-ore-supply-from-simandou-.html',\n",
       " 'https://www.cnbc.com/2022/07/29/euro-area-gdp-q2-2022-growth-accelerates-for-euro-zone.html',\n",
       " 'https://www.cnbc.com/2022/07/29/apples-china-iphone-shipments-surge-in-q2-despite-covid-lockdowns.html',\n",
       " 'https://www.cnbc.com/2022/07/29/us-treasury-yields-edge-lower-after-negative-gdp-reading.html',\n",
       " 'https://www.cnbc.com/2022/07/29/air-travel-chaos-pilots-describe-toxic-culture-and-airline-errors.html',\n",
       " 'https://www.cnbc.com/2022/07/29/new-zealands-borders-are-fully-reopening-after-more-than-two-years.html',\n",
       " 'https://www.cnbc.com/2022/07/29/europe-markets-open-to-close-earnings-economic-data-on-the-agenda.html',\n",
       " 'https://www.cnbc.com/2022/07/29/dollar-strength-is-more-worrisome-than-inflation-for-asia-economist-says.html',\n",
       " 'https://www.cnbc.com/2022/07/29/biden-xi-make-plans-to-meet-us-official-says-xi-warns-on-taiwan.html',\n",
       " 'https://www.cnbc.com/2022/07/29/chinas-xi-faces-major-economic-challenges-says-investor-david-roche.html',\n",
       " 'https://www.cnbc.com/2022/07/28/amazon-says-consumer-demand-still-strong-bucking-broader-retail-gloom.html',\n",
       " 'https://www.cnbc.com/2022/07/29/analyst-says-a-slowdown-could-boost-these-global-stocks.html',\n",
       " 'https://www.cnbc.com/2022/07/29/jpmorgan-buy-the-dip-on-growth-tech-stocks-amid-rebound.html',\n",
       " 'https://www.cnbc.com/2022/07/28/apples-services-slowdown-in-q3-potential-concern-for-investors-.html',\n",
       " 'https://www.cnbc.com/2022/07/28/investing-club-amazon-hopped-over-a-low-bar-this-quarter-and-guided-higher-in-tough-environment.html',\n",
       " 'https://www.cnbc.com/2022/07/29/asia-markets-apple-suppliers-earnings-currencies-oil-wall-street.html',\n",
       " 'https://www.cnbc.com/2022/07/28/investing-club-apples-supply-constraints-werent-as-bad-as-it-thought-leading-to-a-strong-quarter.html',\n",
       " 'https://www.cnbc.com/2022/07/28/cramers-lightning-round-marqeta-is-not-a-buy.html']"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=BeautifulSoup(page7.content,'html.parser')\n",
    "linknews=[]\n",
    "for i in s.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    linknews.append(i.get('href'))\n",
    "linknews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5de93da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews=pd.DataFrame({'Headline':headline,'Time':time,'News Link':linknews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "f8e7b8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>13 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britain's star-studded 'Wagatha Christie' libe...</td>\n",
       "      <td>24 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/-rebekah-vardy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Susquehanna downgrades Roku citing near-term m...</td>\n",
       "      <td>49 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/susquehanna-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stocks making the biggest moves in the premark...</td>\n",
       "      <td>52 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analysts hail Amazon as a port in the storm af...</td>\n",
       "      <td>57 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/analysts-hail-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chevron, Exxon post record quarterly profits a...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/exxon-xom-and-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Higher prices help Procter &amp; Gamble, but Tide ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/procter-gamble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Don't expect a sudden turnaround on supply cha...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/renault-dont-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apple's iPhone sales are creating a strong 'mo...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/apples-iphone-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitcoin hits 6-week high topping $24,000 in a ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/bitcoin-btc-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ukraine denies missile strike on Donbas prison...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cold showers and more: German city turns off t...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/hanover-bans-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>China inches closer to getting alternative iro...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/china-inches-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Euro zone grows 0.7% in the second quarter des...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/euro-area-gdp-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Apple's iPhones held up surprisingly well in C...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/apples-china-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>U.S. Treasury yields rise to end the week</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/us-treasury-yi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Toxic culture and ‘race to the bottom’: Pilots...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/air-travel-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Zealand's borders are fully reopening afte...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/new-zealands-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>European markets climb with earnings, economic...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/europe-markets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dollar strength is more worrisome than inflati...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/dollar-strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Biden-Xi make plans to meet in person, officia...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/biden-xi-make-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>China's Xi is expected to face challenges when...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/chinas-xi-face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amazon says consumer spending remains strong, ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/28/amazon-says-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'Churning out good cash': Analyst says a slowd...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/analyst-says-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JPMorgan says buy the dip in growth names, whi...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/jpmorgan-buy-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Apple's services slowdown is potential concern...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/28/apples-service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Amazon hopped over a low bar this quarter and ...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/28/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hong Kong's Hang Seng drops more than 2% with ...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/29/asia-markets-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Apple's supply-constraints weren't as bad as i...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/28/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cramer's lightning round: Marqeta is not a buy</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/07/28/cramers-lightn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   5 things to know before the stock market opens...    13 Min Ago   \n",
       "1   Britain's star-studded 'Wagatha Christie' libe...    24 Min Ago   \n",
       "2   Susquehanna downgrades Roku citing near-term m...    49 Min Ago   \n",
       "3   Stocks making the biggest moves in the premark...    52 Min Ago   \n",
       "4   Analysts hail Amazon as a port in the storm af...    57 Min Ago   \n",
       "5   Chevron, Exxon post record quarterly profits a...    1 Hour Ago   \n",
       "6   Higher prices help Procter & Gamble, but Tide ...    1 Hour Ago   \n",
       "7   Don't expect a sudden turnaround on supply cha...   2 Hours Ago   \n",
       "8   Apple's iPhone sales are creating a strong 'mo...   3 Hours Ago   \n",
       "9   Bitcoin hits 6-week high topping $24,000 in a ...   3 Hours Ago   \n",
       "10  Ukraine denies missile strike on Donbas prison...   3 Hours Ago   \n",
       "11  Cold showers and more: German city turns off t...   4 Hours Ago   \n",
       "12  China inches closer to getting alternative iro...   5 Hours Ago   \n",
       "13  Euro zone grows 0.7% in the second quarter des...   5 Hours Ago   \n",
       "14  Apple's iPhones held up surprisingly well in C...   7 Hours Ago   \n",
       "15          U.S. Treasury yields rise to end the week   7 Hours Ago   \n",
       "16  Toxic culture and ‘race to the bottom’: Pilots...   8 Hours Ago   \n",
       "17  New Zealand's borders are fully reopening afte...   8 Hours Ago   \n",
       "18  European markets climb with earnings, economic...  10 Hours Ago   \n",
       "19  Dollar strength is more worrisome than inflati...  11 Hours Ago   \n",
       "20  Biden-Xi make plans to meet in person, officia...  11 Hours Ago   \n",
       "21  China's Xi is expected to face challenges when...  11 Hours Ago   \n",
       "22  Amazon says consumer spending remains strong, ...  12 Hours Ago   \n",
       "23  'Churning out good cash': Analyst says a slowd...  12 Hours Ago   \n",
       "24  JPMorgan says buy the dip in growth names, whi...  12 Hours Ago   \n",
       "25  Apple's services slowdown is potential concern...  12 Hours Ago   \n",
       "26  Amazon hopped over a low bar this quarter and ...  13 Hours Ago   \n",
       "27  Hong Kong's Hang Seng drops more than 2% with ...  13 Hours Ago   \n",
       "28  Apple's supply-constraints weren't as bad as i...  13 Hours Ago   \n",
       "29     Cramer's lightning round: Marqeta is not a buy  14 Hours Ago   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/07/29/5-things-to-kn...  \n",
       "1   https://www.cnbc.com/2022/07/29/-rebekah-vardy...  \n",
       "2   https://www.cnbc.com/2022/07/29/susquehanna-do...  \n",
       "3   https://www.cnbc.com/2022/07/29/stocks-making-...  \n",
       "4   https://www.cnbc.com/2022/07/29/analysts-hail-...  \n",
       "5   https://www.cnbc.com/2022/07/29/exxon-xom-and-...  \n",
       "6   https://www.cnbc.com/2022/07/29/procter-gamble...  \n",
       "7   https://www.cnbc.com/2022/07/29/renault-dont-e...  \n",
       "8   https://www.cnbc.com/2022/07/29/apples-iphone-...  \n",
       "9   https://www.cnbc.com/2022/07/29/bitcoin-btc-pr...  \n",
       "10  https://www.cnbc.com/2022/07/29/russia-ukraine...  \n",
       "11  https://www.cnbc.com/2022/07/29/hanover-bans-h...  \n",
       "12  https://www.cnbc.com/2022/07/29/china-inches-c...  \n",
       "13  https://www.cnbc.com/2022/07/29/euro-area-gdp-...  \n",
       "14  https://www.cnbc.com/2022/07/29/apples-china-i...  \n",
       "15  https://www.cnbc.com/2022/07/29/us-treasury-yi...  \n",
       "16  https://www.cnbc.com/2022/07/29/air-travel-cha...  \n",
       "17  https://www.cnbc.com/2022/07/29/new-zealands-b...  \n",
       "18  https://www.cnbc.com/2022/07/29/europe-markets...  \n",
       "19  https://www.cnbc.com/2022/07/29/dollar-strengt...  \n",
       "20  https://www.cnbc.com/2022/07/29/biden-xi-make-...  \n",
       "21  https://www.cnbc.com/2022/07/29/chinas-xi-face...  \n",
       "22  https://www.cnbc.com/2022/07/28/amazon-says-co...  \n",
       "23  https://www.cnbc.com/2022/07/29/analyst-says-a...  \n",
       "24  https://www.cnbc.com/2022/07/29/jpmorgan-buy-t...  \n",
       "25  https://www.cnbc.com/2022/07/28/apples-service...  \n",
       "26  https://www.cnbc.com/2022/07/28/investing-club...  \n",
       "27  https://www.cnbc.com/2022/07/29/asia-markets-a...  \n",
       "28  https://www.cnbc.com/2022/07/28/investing-club...  \n",
       "29  https://www.cnbc.com/2022/07/28/cramers-lightn...  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7d9b4",
   "metadata": {},
   "source": [
    "Question 8: program to scrape details of most downloaded articles in last 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3b88b144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Reward', 'is', 'enough'],\n",
       " ['Making', 'sense', 'of', 'raw', 'input'],\n",
       " ['Law',\n",
       "  'and',\n",
       "  'logic:',\n",
       "  'A',\n",
       "  'review',\n",
       "  'from',\n",
       "  'an',\n",
       "  'argumentation',\n",
       "  'perspective'],\n",
       " ['Creativity', 'and', 'artificial', 'intelligence'],\n",
       " ['Artificial',\n",
       "  'cognition',\n",
       "  'for',\n",
       "  'social',\n",
       "  'human–robot',\n",
       "  'interaction:',\n",
       "  'An',\n",
       "  'implementation'],\n",
       " ['Explanation',\n",
       "  'in',\n",
       "  'artificial',\n",
       "  'intelligence:',\n",
       "  'Insights',\n",
       "  'from',\n",
       "  'the',\n",
       "  'social',\n",
       "  'sciences'],\n",
       " ['Making', 'sense', 'of', 'sensory', 'input'],\n",
       " ['Conflict-based', 'search', 'for', 'optimal', 'multi-agent', 'pathfinding'],\n",
       " ['Between',\n",
       "  'MDPs',\n",
       "  'and',\n",
       "  'semi-MDPs:',\n",
       "  'A',\n",
       "  'framework',\n",
       "  'for',\n",
       "  'temporal',\n",
       "  'abstraction',\n",
       "  'in',\n",
       "  'reinforcement',\n",
       "  'learning'],\n",
       " ['The',\n",
       "  'Hanabi',\n",
       "  'challenge:',\n",
       "  'A',\n",
       "  'new',\n",
       "  'frontier',\n",
       "  'for',\n",
       "  'AI',\n",
       "  'research'],\n",
       " ['Evaluating',\n",
       "  'XAI:',\n",
       "  'A',\n",
       "  'comparison',\n",
       "  'of',\n",
       "  'rule-based',\n",
       "  'and',\n",
       "  'example-based',\n",
       "  'explanations'],\n",
       " ['Argumentation', 'in', 'artificial', 'intelligence'],\n",
       " ['Algorithms',\n",
       "  'for',\n",
       "  'computing',\n",
       "  'strategies',\n",
       "  'in',\n",
       "  'two-player',\n",
       "  'simultaneous',\n",
       "  'move',\n",
       "  'games'],\n",
       " ['Multiple', 'object', 'tracking:', 'A', 'literature', 'review'],\n",
       " ['Selection',\n",
       "  'of',\n",
       "  'relevant',\n",
       "  'features',\n",
       "  'and',\n",
       "  'examples',\n",
       "  'in',\n",
       "  'machine',\n",
       "  'learning'],\n",
       " ['A',\n",
       "  'survey',\n",
       "  'of',\n",
       "  'inverse',\n",
       "  'reinforcement',\n",
       "  'learning:',\n",
       "  'Challenges,',\n",
       "  'methods',\n",
       "  'and',\n",
       "  'progress'],\n",
       " ['Explaining',\n",
       "  'individual',\n",
       "  'predictions',\n",
       "  'when',\n",
       "  'features',\n",
       "  'are',\n",
       "  'dependent:',\n",
       "  'More',\n",
       "  'accurate',\n",
       "  'approximations',\n",
       "  'to',\n",
       "  'Shapley',\n",
       "  'values'],\n",
       " ['A',\n",
       "  'review',\n",
       "  'of',\n",
       "  'possible',\n",
       "  'effects',\n",
       "  'of',\n",
       "  'cognitive',\n",
       "  'biases',\n",
       "  'on',\n",
       "  'interpretation',\n",
       "  'of',\n",
       "  'rule-based',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'models'],\n",
       " ['Integrating',\n",
       "  'social',\n",
       "  'power',\n",
       "  'into',\n",
       "  'the',\n",
       "  'decision-making',\n",
       "  'of',\n",
       "  'cognitive',\n",
       "  'agents'],\n",
       " [\"“That's\",\n",
       "  '(not)',\n",
       "  'the',\n",
       "  'output',\n",
       "  'I',\n",
       "  'expected!”',\n",
       "  'On',\n",
       "  'the',\n",
       "  'role',\n",
       "  'of',\n",
       "  'end',\n",
       "  'user',\n",
       "  'expectations',\n",
       "  'in',\n",
       "  'creating',\n",
       "  'explanations',\n",
       "  'of',\n",
       "  'AI',\n",
       "  'systems'],\n",
       " ['Explaining',\n",
       "  'black-box',\n",
       "  'classifiers',\n",
       "  'using',\n",
       "  'post-hoc',\n",
       "  'explanations-by-example:',\n",
       "  'The',\n",
       "  'effect',\n",
       "  'of',\n",
       "  'explanations',\n",
       "  'and',\n",
       "  'error-rates',\n",
       "  'in',\n",
       "  'XAI',\n",
       "  'user',\n",
       "  'studies'],\n",
       " ['Algorithm', 'runtime', 'prediction:', 'Methods', '&', 'evaluation'],\n",
       " ['Wrappers', 'for', 'feature', 'subset', 'selection'],\n",
       " ['Commonsense',\n",
       "  'visual',\n",
       "  'sensemaking',\n",
       "  'for',\n",
       "  'autonomous',\n",
       "  'driving',\n",
       "  '–',\n",
       "  'On',\n",
       "  'generalised',\n",
       "  'neurosymbolic',\n",
       "  'online',\n",
       "  'abduction',\n",
       "  'integrating',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'semantics'],\n",
       " ['Quantum', 'computation,', 'quantum', 'theory', 'and', 'AI']]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page8=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup8=BeautifulSoup(page8.content,'html.parser')\n",
    "articles=[]\n",
    "for i in soup8.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    articles.append(i.text.split())\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "e7fe2b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author=[]\n",
    "for i in soup8.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "6f26e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f3600484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup8.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "  date.append(i.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2cbe4bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links=[]\n",
    "for i in soup8.find_all('a',class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    links.append(i.get('href'))\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "4a3c9233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(links),len(date),len(author),len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "21864cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date of Publish</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Reward, is, enough]</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Making, sense, of, raw, input]</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Law, and, logic:, A, review, from, an, argume...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Creativity, and, artificial, intelligence]</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Artificial, cognition, for, social, human–rob...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Explanation, in, artificial, intelligence:, I...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Making, sense, of, sensory, input]</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Conflict-based, search, for, optimal, multi-a...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Between, MDPs, and, semi-MDPs:, A, framework,...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[The, Hanabi, challenge:, A, new, frontier, fo...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Evaluating, XAI:, A, comparison, of, rule-bas...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Argumentation, in, artificial, intelligence]</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Algorithms, for, computing, strategies, in, t...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Multiple, object, tracking:, A, literature, r...</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Selection, of, relevant, features, and, examp...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[A, survey, of, inverse, reinforcement, learni...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Explaining, individual, predictions, when, fe...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[A, review, of, possible, effects, of, cogniti...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Integrating, social, power, into, the, decisi...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[“That's, (not), the, output, I, expected!”, O...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[Explaining, black-box, classifiers, using, po...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[Algorithm, runtime, prediction:, Methods, &amp;, ...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[Wrappers, for, feature, subset, selection]</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[Commonsense, visual, sensemaking, for, autono...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[Quantum, computation,, quantum, theory, and, AI]</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  \\\n",
       "0                                [Reward, is, enough]   \n",
       "1                     [Making, sense, of, raw, input]   \n",
       "2   [Law, and, logic:, A, review, from, an, argume...   \n",
       "3         [Creativity, and, artificial, intelligence]   \n",
       "4   [Artificial, cognition, for, social, human–rob...   \n",
       "5   [Explanation, in, artificial, intelligence:, I...   \n",
       "6                 [Making, sense, of, sensory, input]   \n",
       "7   [Conflict-based, search, for, optimal, multi-a...   \n",
       "8   [Between, MDPs, and, semi-MDPs:, A, framework,...   \n",
       "9   [The, Hanabi, challenge:, A, new, frontier, fo...   \n",
       "10  [Evaluating, XAI:, A, comparison, of, rule-bas...   \n",
       "11      [Argumentation, in, artificial, intelligence]   \n",
       "12  [Algorithms, for, computing, strategies, in, t...   \n",
       "13  [Multiple, object, tracking:, A, literature, r...   \n",
       "14  [Selection, of, relevant, features, and, examp...   \n",
       "15  [A, survey, of, inverse, reinforcement, learni...   \n",
       "16  [Explaining, individual, predictions, when, fe...   \n",
       "17  [A, review, of, possible, effects, of, cogniti...   \n",
       "18  [Integrating, social, power, into, the, decisi...   \n",
       "19  [“That's, (not), the, output, I, expected!”, O...   \n",
       "20  [Explaining, black-box, classifiers, using, po...   \n",
       "21  [Algorithm, runtime, prediction:, Methods, &, ...   \n",
       "22        [Wrappers, for, feature, subset, selection]   \n",
       "23  [Commonsense, visual, sensemaking, for, autono...   \n",
       "24  [Quantum, computation,, quantum, theory, and, AI]   \n",
       "\n",
       "                                               Author Date of Publish  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfarticle=pd.DataFrame({'Article':articles,'Author':author,'Date of Publish':date,'Link':links})\n",
    "dfarticle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db156dd9",
   "metadata": {},
   "source": [
    "Question 9: program to scrape details of a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "6d31b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page9=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup9=BeautifulSoup(page9.content,'html.parser')\n",
    "resname=[]\n",
    "cuisine=[]\n",
    "location=[]\n",
    "rating=[]\n",
    "imgurl=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "53113fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Castle', 'Barbeque'],\n",
       " ['Jungle', 'Jamboree'],\n",
       " ['Castle', 'Barbeque'],\n",
       " ['Cafe', 'Knosh'],\n",
       " ['The', 'Barbeque', 'Company'],\n",
       " ['India', 'Grill'],\n",
       " ['Delhi', 'Barbeque'],\n",
       " ['The', 'Monarch', '-', 'Bar', 'Be', 'Que', 'Village'],\n",
       " ['Indian', 'Grill', 'Room']]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup9.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    resname.append(i.text.split())\n",
    "resname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "990f2dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Connaught', 'Place,', 'Central', 'Delhi'],\n",
       " ['3CS', 'Mall,Lajpat', 'Nagar', '-', '3,', 'South', 'Delhi'],\n",
       " ['Pacific', 'Mall,Tagore', 'Garden,', 'West', 'Delhi'],\n",
       " ['The',\n",
       "  'Leela',\n",
       "  'Ambience',\n",
       "  'Convention',\n",
       "  'Hotel,Shahdara,',\n",
       "  'East',\n",
       "  'Delhi'],\n",
       " ['Gardens', 'Galleria,Sector', '38A,', 'Noida'],\n",
       " ['Hilton', 'Garden', 'Inn,Saket,', 'South', 'Delhi'],\n",
       " ['Taurus', 'Sarovar', 'Portico,Mahipalpur,', 'South', 'Delhi'],\n",
       " ['Indirapuram', 'Habitat', 'Centre,Indirapuram,', 'Ghaziabad'],\n",
       " ['Suncity', 'Business', 'Tower,Golf', 'Course', 'Road,', 'Gurgaon']]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup9.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text.split())\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "bf450cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['North', 'Indian,', 'Chinese'],\n",
       " ['North', 'Indian,', 'Asian,', 'Italian'],\n",
       " ['Chinese,', 'North', 'Indian'],\n",
       " ['Italian,', 'Continental'],\n",
       " ['North', 'Indian,', 'Chinese'],\n",
       " ['North', 'Indian,', 'Italian'],\n",
       " ['North', 'Indian'],\n",
       " ['North', 'Indian'],\n",
       " ['North', 'Indian,', 'Mughlai']]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine=[]\n",
    "for i in soup9.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split()[6:])\n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "fea6e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '3.9', '3.9', '4.3', '4', '3.9', '3.7', '3.8', '4.3']"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in soup9.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "8b0328f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/h/c/p3643-144497865356209fdd65746.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/v/f/p52501-16006856545f68865616659.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgurl=[]\n",
    "for i in soup9.find_all('img',class_=\"no-img\"):\n",
    "    imgurl.append(i.get('data-src'))\n",
    "imgurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "b1867140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(resname),len(cuisine),len(location),len(rating),len(imgurl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "d09850d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>image url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Castle, Barbeque]</td>\n",
       "      <td>[Connaught, Place,, Central, Delhi]</td>\n",
       "      <td>[North, Indian,, Chinese]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Jungle, Jamboree]</td>\n",
       "      <td>[3CS, Mall,Lajpat, Nagar, -, 3,, South, Delhi]</td>\n",
       "      <td>[North, Indian,, Asian,, Italian]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Castle, Barbeque]</td>\n",
       "      <td>[Pacific, Mall,Tagore, Garden,, West, Delhi]</td>\n",
       "      <td>[Chinese,, North, Indian]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Cafe, Knosh]</td>\n",
       "      <td>[The, Leela, Ambience, Convention, Hotel,Shahd...</td>\n",
       "      <td>[Italian,, Continental]</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, Barbeque, Company]</td>\n",
       "      <td>[Gardens, Galleria,Sector, 38A,, Noida]</td>\n",
       "      <td>[North, Indian,, Chinese]</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[India, Grill]</td>\n",
       "      <td>[Hilton, Garden, Inn,Saket,, South, Delhi]</td>\n",
       "      <td>[North, Indian,, Italian]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Delhi, Barbeque]</td>\n",
       "      <td>[Taurus, Sarovar, Portico,Mahipalpur,, South, ...</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[The, Monarch, -, Bar, Be, Que, Village]</td>\n",
       "      <td>[Indirapuram, Habitat, Centre,Indirapuram,, Gh...</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Indian, Grill, Room]</td>\n",
       "      <td>[Suncity, Business, Tower,Golf, Course, Road,,...</td>\n",
       "      <td>[North, Indian,, Mughlai]</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name  \\\n",
       "0                        [Castle, Barbeque]   \n",
       "1                        [Jungle, Jamboree]   \n",
       "2                        [Castle, Barbeque]   \n",
       "3                             [Cafe, Knosh]   \n",
       "4                  [The, Barbeque, Company]   \n",
       "5                            [India, Grill]   \n",
       "6                         [Delhi, Barbeque]   \n",
       "7  [The, Monarch, -, Bar, Be, Que, Village]   \n",
       "8                     [Indian, Grill, Room]   \n",
       "\n",
       "                                            Location  \\\n",
       "0                [Connaught, Place,, Central, Delhi]   \n",
       "1     [3CS, Mall,Lajpat, Nagar, -, 3,, South, Delhi]   \n",
       "2       [Pacific, Mall,Tagore, Garden,, West, Delhi]   \n",
       "3  [The, Leela, Ambience, Convention, Hotel,Shahd...   \n",
       "4            [Gardens, Galleria,Sector, 38A,, Noida]   \n",
       "5         [Hilton, Garden, Inn,Saket,, South, Delhi]   \n",
       "6  [Taurus, Sarovar, Portico,Mahipalpur,, South, ...   \n",
       "7  [Indirapuram, Habitat, Centre,Indirapuram,, Gh...   \n",
       "8  [Suncity, Business, Tower,Golf, Course, Road,,...   \n",
       "\n",
       "                             Cuisine Rating  \\\n",
       "0          [North, Indian,, Chinese]    4.1   \n",
       "1  [North, Indian,, Asian,, Italian]    3.9   \n",
       "2          [Chinese,, North, Indian]    3.9   \n",
       "3            [Italian,, Continental]    4.3   \n",
       "4          [North, Indian,, Chinese]      4   \n",
       "5          [North, Indian,, Italian]    3.9   \n",
       "6                    [North, Indian]    3.7   \n",
       "7                    [North, Indian]    3.8   \n",
       "8          [North, Indian,, Mughlai]    4.3   \n",
       "\n",
       "                                           image url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdine=pd.DataFrame({'Name':resname,'Location':location,'Cuisine':cuisine,'Rating':rating,'image url':imgurl})\n",
    "dfdine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e2e26",
   "metadata": {},
   "source": [
    "Question 10:python program to scrape the details of top publications from Google Scholar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "b81cced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "page10=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup10=BeautifulSoup(page10.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "4537a457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.'],\n",
       " ['2.'],\n",
       " ['3.'],\n",
       " ['4.'],\n",
       " ['5.'],\n",
       " ['6.'],\n",
       " ['7.'],\n",
       " ['8.'],\n",
       " ['9.'],\n",
       " ['10.'],\n",
       " ['11.'],\n",
       " ['12.'],\n",
       " ['13.'],\n",
       " ['14.'],\n",
       " ['15.'],\n",
       " ['16.'],\n",
       " ['17.'],\n",
       " ['18.'],\n",
       " ['19.'],\n",
       " ['20.'],\n",
       " ['21.'],\n",
       " ['22.'],\n",
       " ['23.'],\n",
       " ['24.'],\n",
       " ['25.'],\n",
       " ['26.'],\n",
       " ['27.'],\n",
       " ['28.'],\n",
       " ['29.'],\n",
       " ['30.'],\n",
       " ['31.'],\n",
       " ['32.'],\n",
       " ['33.'],\n",
       " ['34.'],\n",
       " ['35.'],\n",
       " ['36.'],\n",
       " ['37.'],\n",
       " ['38.'],\n",
       " ['39.'],\n",
       " ['40.'],\n",
       " ['41.'],\n",
       " ['42.'],\n",
       " ['43.'],\n",
       " ['44.'],\n",
       " ['45.'],\n",
       " ['46.'],\n",
       " ['47.'],\n",
       " ['48.'],\n",
       " ['49.'],\n",
       " ['50.'],\n",
       " ['51.'],\n",
       " ['52.'],\n",
       " ['53.'],\n",
       " ['54.'],\n",
       " ['55.'],\n",
       " ['56.'],\n",
       " ['57.'],\n",
       " ['58.'],\n",
       " ['59.'],\n",
       " ['60.'],\n",
       " ['61.'],\n",
       " ['62.'],\n",
       " ['63.'],\n",
       " ['64.'],\n",
       " ['65.'],\n",
       " ['66.'],\n",
       " ['67.'],\n",
       " ['68.'],\n",
       " ['69.'],\n",
       " ['70.'],\n",
       " ['71.'],\n",
       " ['72.'],\n",
       " ['73.'],\n",
       " ['74.'],\n",
       " ['75.'],\n",
       " ['76.'],\n",
       " ['77.'],\n",
       " ['78.'],\n",
       " ['79.'],\n",
       " ['80.'],\n",
       " ['81.'],\n",
       " ['82.'],\n",
       " ['83.'],\n",
       " ['84.'],\n",
       " ['85.'],\n",
       " ['86.'],\n",
       " ['87.'],\n",
       " ['88.'],\n",
       " ['89.'],\n",
       " ['90.'],\n",
       " ['91.'],\n",
       " ['92.'],\n",
       " ['93.'],\n",
       " ['94.'],\n",
       " ['95.'],\n",
       " ['96.'],\n",
       " ['97.'],\n",
       " ['98.'],\n",
       " ['99.'],\n",
       " ['100.']]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "for i in soup10.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text.split())\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f14880ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Nature'],\n",
       " ['The', 'New', 'England', 'Journal', 'of', 'Medicine'],\n",
       " ['Science'],\n",
       " ['IEEE/CVF',\n",
       "  'Conference',\n",
       "  'on',\n",
       "  'Computer',\n",
       "  'Vision',\n",
       "  'and',\n",
       "  'Pattern',\n",
       "  'Recognition'],\n",
       " ['The', 'Lancet'],\n",
       " ['Advanced', 'Materials'],\n",
       " ['Nature', 'Communications'],\n",
       " ['Cell'],\n",
       " ['International', 'Conference', 'on', 'Learning', 'Representations'],\n",
       " ['Neural', 'Information', 'Processing', 'Systems'],\n",
       " ['JAMA'],\n",
       " ['Chemical', 'Reviews'],\n",
       " ['Proceedings', 'of', 'the', 'National', 'Academy', 'of', 'Sciences'],\n",
       " ['Angewandte', 'Chemie'],\n",
       " ['Chemical', 'Society', 'Reviews'],\n",
       " ['Journal', 'of', 'the', 'American', 'Chemical', 'Society'],\n",
       " ['IEEE/CVF', 'International', 'Conference', 'on', 'Computer', 'Vision'],\n",
       " ['Nucleic', 'Acids', 'Research'],\n",
       " ['International', 'Conference', 'on', 'Machine', 'Learning'],\n",
       " ['Nature', 'Medicine'],\n",
       " ['Renewable', 'and', 'Sustainable', 'Energy', 'Reviews'],\n",
       " ['Science', 'of', 'The', 'Total', 'Environment'],\n",
       " ['Advanced', 'Energy', 'Materials'],\n",
       " ['Journal', 'of', 'Clinical', 'Oncology'],\n",
       " ['ACS', 'Nano'],\n",
       " ['Journal', 'of', 'Cleaner', 'Production'],\n",
       " ['Advanced', 'Functional', 'Materials'],\n",
       " ['Physical', 'Review', 'Letters'],\n",
       " ['Scientific', 'Reports'],\n",
       " ['The', 'Lancet', 'Oncology'],\n",
       " ['Energy', '&', 'Environmental', 'Science'],\n",
       " ['IEEE', 'Access'],\n",
       " ['PLoS', 'ONE'],\n",
       " ['Science', 'Advances'],\n",
       " ['Journal', 'of', 'the', 'American', 'College', 'of', 'Cardiology'],\n",
       " ['Applied', 'Catalysis', 'B:', 'Environmental'],\n",
       " ['Nature', 'Genetics'],\n",
       " ['BMJ'],\n",
       " ['Circulation'],\n",
       " ['European', 'Conference', 'on', 'Computer', 'Vision'],\n",
       " ['International', 'Journal', 'of', 'Molecular', 'Sciences'],\n",
       " ['Nature', 'Materials'],\n",
       " ['Chemical', 'engineering', 'journal'],\n",
       " ['AAAI', 'Conference', 'on', 'Artificial', 'Intelligence'],\n",
       " ['Journal', 'of', 'Materials', 'Chemistry', 'A'],\n",
       " ['ACS', 'Applied', 'Materials', '&', 'Interfaces'],\n",
       " ['Nature', 'Biotechnology'],\n",
       " ['The', 'Lancet', 'Infectious', 'Diseases'],\n",
       " ['Frontiers', 'in', 'Immunology'],\n",
       " ['Applied', 'Energy'],\n",
       " ['Nano', 'Energy'],\n",
       " ['Nature', 'Energy'],\n",
       " ['Meeting',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Association',\n",
       "  'for',\n",
       "  'Computational',\n",
       "  'Linguistics',\n",
       "  '(ACL)'],\n",
       " ['The', 'Astrophysical', 'Journal'],\n",
       " ['Gastroenterology'],\n",
       " ['Nature', 'Methods'],\n",
       " ['IEEE',\n",
       "  'Transactions',\n",
       "  'on',\n",
       "  'Pattern',\n",
       "  'Analysis',\n",
       "  'and',\n",
       "  'Machine',\n",
       "  'Intelligence'],\n",
       " ['Cochrane', 'Database', 'of', 'Systematic', 'Reviews'],\n",
       " ['Blood'],\n",
       " ['Neuron'],\n",
       " ['Nano', 'Letters'],\n",
       " ['Morbidity', 'and', 'Mortality', 'Weekly', 'Report'],\n",
       " ['European', 'Heart', 'Journal'],\n",
       " ['Nature', 'Nanotechnology'],\n",
       " ['ACS', 'Catalysis'],\n",
       " ['Nature', 'Neuroscience'],\n",
       " ['American', 'Economic', 'Review'],\n",
       " ['Journal', 'of', 'High', 'Energy', 'Physics'],\n",
       " ['IEEE', 'Communications', 'Surveys', '&', 'Tutorials'],\n",
       " ['Annals', 'of', 'Oncology'],\n",
       " ['Nutrients'],\n",
       " ['Accounts', 'of', 'Chemical', 'Research'],\n",
       " ['Immunity'],\n",
       " ['Environmental', 'Science', '&', 'Technology'],\n",
       " ['Nature', 'Reviews.', 'Molecular', 'Cell', 'Biology'],\n",
       " ['Gut'],\n",
       " ['Physical', 'Review', 'D'],\n",
       " ['ACS', 'Energy', 'Letters'],\n",
       " ['Monthly', 'Notices', 'of', 'the', 'Royal', 'Astronomical', 'Society'],\n",
       " ['Conference',\n",
       "  'on',\n",
       "  'Empirical',\n",
       "  'Methods',\n",
       "  'in',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  '(EMNLP)'],\n",
       " ['Clinical', 'Infectious', 'Diseases'],\n",
       " ['Cell', 'Metabolism'],\n",
       " ['Nature', 'Reviews', 'Immunology'],\n",
       " ['Joule'],\n",
       " ['Nature', 'Photonics'],\n",
       " ['International',\n",
       "  'Journal',\n",
       "  'of',\n",
       "  'Environmental',\n",
       "  'Research',\n",
       "  'and',\n",
       "  'Public',\n",
       "  'Health'],\n",
       " ['Environmental', 'Pollution'],\n",
       " ['Computers', 'in', 'Human', 'Behavior'],\n",
       " ['Frontiers', 'in', 'Microbiology'],\n",
       " ['Nature', 'Physics'],\n",
       " ['Small'],\n",
       " ['Cell', 'Reports'],\n",
       " ['Molecular', 'Cell'],\n",
       " ['Clinical', 'Cancer', 'Research'],\n",
       " ['Bioresource', 'Technology'],\n",
       " ['Journal', 'of', 'Business', 'Research'],\n",
       " ['Molecular', 'Cancer'],\n",
       " ['Sensors'],\n",
       " ['Nature', 'Climate', 'Change'],\n",
       " ['IEEE', 'Internet', 'of', 'Things', 'Journal']]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub=[]\n",
    "for i in soup10.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    pub.append(i.text.split())\n",
    "pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "9ca127cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444',\n",
       " '432',\n",
       " '401',\n",
       " '389',\n",
       " '354',\n",
       " '312',\n",
       " '307',\n",
       " '300',\n",
       " '286',\n",
       " '278',\n",
       " '267',\n",
       " '265',\n",
       " '256',\n",
       " '245',\n",
       " '244',\n",
       " '242',\n",
       " '239',\n",
       " '238',\n",
       " '237',\n",
       " '235',\n",
       " '227',\n",
       " '225',\n",
       " '220',\n",
       " '213',\n",
       " '211',\n",
       " '211',\n",
       " '210',\n",
       " '207',\n",
       " '206',\n",
       " '202',\n",
       " '202',\n",
       " '200',\n",
       " '198',\n",
       " '197',\n",
       " '195',\n",
       " '192',\n",
       " '191',\n",
       " '190',\n",
       " '189',\n",
       " '186',\n",
       " '183',\n",
       " '181',\n",
       " '181',\n",
       " '180',\n",
       " '178',\n",
       " '177',\n",
       " '175',\n",
       " '173',\n",
       " '173',\n",
       " '173',\n",
       " '172',\n",
       " '170',\n",
       " '169',\n",
       " '167',\n",
       " '166',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '164',\n",
       " '164',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '162',\n",
       " '160',\n",
       " '160',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '158',\n",
       " '158',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '154',\n",
       " '153',\n",
       " '153',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '151',\n",
       " '151',\n",
       " '150',\n",
       " '149',\n",
       " '149',\n",
       " '146',\n",
       " '146',\n",
       " '145',\n",
       " '145',\n",
       " '145',\n",
       " '144',\n",
       " '144']"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[]\n",
    "for i in soup10.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    index.append(i.text)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "233562de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667',\n",
       " '780',\n",
       " '614',\n",
       " '627',\n",
       " '635',\n",
       " '418',\n",
       " '428',\n",
       " '505',\n",
       " '533',\n",
       " '436',\n",
       " '425',\n",
       " '444',\n",
       " '364',\n",
       " '332',\n",
       " '386',\n",
       " '344',\n",
       " '415',\n",
       " '550',\n",
       " '421',\n",
       " '389',\n",
       " '324',\n",
       " '311',\n",
       " '300',\n",
       " '315',\n",
       " '277',\n",
       " '273',\n",
       " '280',\n",
       " '294',\n",
       " '274',\n",
       " '329',\n",
       " '290',\n",
       " '303',\n",
       " '278',\n",
       " '294',\n",
       " '276',\n",
       " '246',\n",
       " '297',\n",
       " '307',\n",
       " '301',\n",
       " '321',\n",
       " '253',\n",
       " '265',\n",
       " '224',\n",
       " '296',\n",
       " '220',\n",
       " '223',\n",
       " '315',\n",
       " '296',\n",
       " '228',\n",
       " '217',\n",
       " '232',\n",
       " '314',\n",
       " '304',\n",
       " '234',\n",
       " '254',\n",
       " '296',\n",
       " '293',\n",
       " '243',\n",
       " '229',\n",
       " '231',\n",
       " '207',\n",
       " '302',\n",
       " '265',\n",
       " '264',\n",
       " '220',\n",
       " '248',\n",
       " '263',\n",
       " '220',\n",
       " '304',\n",
       " '243',\n",
       " '214',\n",
       " '211',\n",
       " '242',\n",
       " '214',\n",
       " '340',\n",
       " '235',\n",
       " '217',\n",
       " '212',\n",
       " '194',\n",
       " '249',\n",
       " '278',\n",
       " '211',\n",
       " '292',\n",
       " '233',\n",
       " '228',\n",
       " '225',\n",
       " '222',\n",
       " '214',\n",
       " '225',\n",
       " '222',\n",
       " '196',\n",
       " '205',\n",
       " '202',\n",
       " '201',\n",
       " '190',\n",
       " '233',\n",
       " '209',\n",
       " '201',\n",
       " '228',\n",
       " '212']"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median=[]\n",
    "for i in soup10.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    median.append(i.text)\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "22c38b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscholar=pd.DataFrame({'Rank':rank,'Publication':pub,'H5 index':index,'H5 median':median})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "0a5193ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>H5 index</th>\n",
       "      <th>H5 median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.]</td>\n",
       "      <td>[Nature]</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.]</td>\n",
       "      <td>[The, New, England, Journal, of, Medicine]</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3.]</td>\n",
       "      <td>[Science]</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.]</td>\n",
       "      <td>[IEEE/CVF, Conference, on, Computer, Vision, a...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5.]</td>\n",
       "      <td>[The, Lancet]</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[96.]</td>\n",
       "      <td>[Journal, of, Business, Research]</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[97.]</td>\n",
       "      <td>[Molecular, Cancer]</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[98.]</td>\n",
       "      <td>[Sensors]</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[99.]</td>\n",
       "      <td>[Nature, Climate, Change]</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[100.]</td>\n",
       "      <td>[IEEE, Internet, of, Things, Journal]</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank                                        Publication H5 index  \\\n",
       "0     [1.]                                           [Nature]      444   \n",
       "1     [2.]         [The, New, England, Journal, of, Medicine]      432   \n",
       "2     [3.]                                          [Science]      401   \n",
       "3     [4.]  [IEEE/CVF, Conference, on, Computer, Vision, a...      389   \n",
       "4     [5.]                                      [The, Lancet]      354   \n",
       "..     ...                                                ...      ...   \n",
       "95   [96.]                  [Journal, of, Business, Research]      145   \n",
       "96   [97.]                                [Molecular, Cancer]      145   \n",
       "97   [98.]                                          [Sensors]      145   \n",
       "98   [99.]                          [Nature, Climate, Change]      144   \n",
       "99  [100.]              [IEEE, Internet, of, Things, Journal]      144   \n",
       "\n",
       "   H5 median  \n",
       "0        667  \n",
       "1        780  \n",
       "2        614  \n",
       "3        627  \n",
       "4        635  \n",
       "..       ...  \n",
       "95       233  \n",
       "96       209  \n",
       "97       201  \n",
       "98       228  \n",
       "99       212  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97768b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
